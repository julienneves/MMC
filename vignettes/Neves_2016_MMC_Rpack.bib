
@article{dufour_monte_2006,
	title = {Monte {Carlo} tests with nuisance parameters: {A} general approach to finite-sample inference and nonstandard asymptotics},
	volume = {133},
	shorttitle = {Monte {Carlo} tests with nuisance parameters},
	abstract = {The technique of Monte Carlo (MC) tests [Dwass (1957), Barnard (1963)] provides an attractive method of building exact tests from statistics whose finite sample distribution is intractable but can be simulated (provided it does not involve nuisance parameters). We extend this method in two ways: first, by allowing for MC tests based on exchangeable possibly discrete test statistics; second, by generalizing the method to statistics whose null distributions involve nuisance parameters (maximized MC tests, MMC). Simplified asymptotically justified versions of the MMC method are also proposed and it is shown that they provide a simple way of improving standard asymptotics and dealing with nonstandard asymptotics (e.g., unit root asymptotics). Parametric bootstrap tests may be interpreted as a simplified version of the MMC method (without the general validity properties of the latter).{\textless}P{\textgreater}(This abstract was borrowed from another version of this item.)},
	number = {2},
	urldate = {2016-07-29},
	journal = {Journal of Econometrics},
	author = {Dufour, Jean-Marie},
	year = {2006},
	note = {bibtex: dufour\_monte\_2006},
	pages = {443--477},
	file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\HFQRWTDN\\v133y2006i2p443-477.html:text/html}
}

@article{haldrup_robustness_2002,
	title = {On the {Robustness} of {Unit} {Root} {Tests} in the {Presence} of {Double} {Unit} {Roots}},
	volume = {23},
	issn = {1467-9892},
	doi = {10.1111/1467-9892.00260},
	number = {2},
	journal = {Journal of Time Series Analysis},
	author = {Haldrup, Niels and Lildholdt, Peter},
	year = {2002},
	note = {bibtex: haldrup\_robustness\_2002},
	keywords = {Dickey–Fuller test, I(1) versus I(2), Phillips–Perron test, Unit root tests},
	pages = {155--171}
}

@article{dufour_wald_2013,
	title = {Wald tests when restrictions are locally singular},
	abstract = {Wald-type tests are convenient because they allow one to test a wide array of linear and nonlinear restrictions from a single unrestricted estimator; we focus on the problem of implementing Wald-type tests for nonlinear restrictions. We provide examples showing that Wald statistics in non-regular cases can have several asymptotic distributions; the usual critical values based on a chi-square distribution can both lead to under-rejections and over-rejections; indeed, the Wald statistic may diverge under the null hypothesis. We study the asymptotic distribution of Wald-type statistics for the class of polynomial restrictions and show that the Wald statistic either has a non-degenerate asymptotic distribution, or diverges to infinity. We provide conditions for convergence and a general characterization of this distribution. We provide bounds on the asymptotic distribution (when it exists). In several cases of interest, this bound yields an easily available conservative critical value. We propose an adaptive consistent strategy for determining whether the asymptotic distribution exists and which form it takes.},
	urldate = {2016-07-29},
	journal = {arXiv:1312.0569 [math, stat]},
	author = {Dufour, Jean-Marie and Renault, Eric and Zinde-Walsh, Victoria},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.0569 
bibtex: dufour\_wald\_2013},
	keywords = {62FO3, Mathematics - Statistics Theory},
	file = {arXiv\:1312.0569 PDF:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\3B58HVVV\\Dufour et al. - 2013 - Wald tests when restrictions are locally singular.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\FNZV6TQF\\1312.html:text/html}
}

@incollection{dufour_monte_2003,
	title = {Monte {Carlo} {Test} {Methods} in {Econometrics}},
	copyright = {Copyright © 2001, 2003 by Blackwell Publishing Ltd},
	isbn = {978-0-470-99624-9},
	abstract = {This chapter contains section titled:

* INTRODUCTION
* STATISTICAL ISSUES: A PRACTICAL APPROACH TO CORE QUESTIONS
* THE MONTE CARLO TEST TECHNIQUE: AN EXACT RANDOMIZED TEST PROCEDURE * MONTE CARLO TESTS: ECONOMETRIC APPLICATIONS
* CONCLUSION},
	language = {en},
	urldate = {2016-07-29},
	booktitle = {A {Companion} to {Theoretical} {Econometrics}},
	publisher = {Blackwell Publishing Ltd},
	author = {Dufour, Jean-Marie and Khalaf, Lynda},
	editor = {Baltagi, Badi H.},
	year = {2003},
	note = {bibtex: dufour\_monte\_2003},
	keywords = {econometrics, Monte Carlo test methods, multivariate regression models, nuisance parameters, randomized test procedure},
	pages = {494--519},
	file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\8RUIDBI8\\summary.html:text/html}
}

@article{dwass_modified_1957,
	title = {Modified {Randomization} {Tests} for {Nonparametric} {Hypotheses}},
	volume = {28},
	issn = {0003-4851, 2168-8990},
	doi = {10.1214/aoms/1177707045},
	abstract = {Suppose X1,⋯,Xm,Y1,⋯,YnX\_1, {\textbackslash}cdots, X\_m, Y\_1, {\textbackslash}cdots, Y\_n are m+n=Nm + n = N independent random variables, the XX's identically distributed and the YY's identically distributed, each with a continuous cdf. Let z=(z1,⋯,zm,zm+1,⋯,zN)=(x1,⋯,xm,y1,⋯,yn)z = (z\_1, {\textbackslash}cdots, z\_m, z\_\{m + 1\}, {\textbackslash}cdots, z\_N) = (x\_1, {\textbackslash}cdots, x\_m, y\_1, {\textbackslash}cdots, y\_n) represent an observation on the NN random variables and let u(z)=(1/m)m∑i=1zi−(1/n)N∑i=m+1zi=ˉx−ˉyu(z) = (1/m) {\textbackslash}sum{\textasciicircum}m\_\{i = 1\} z\_i - (1/n) {\textbackslash}sum{\textasciicircum}N\_\{i = m + 1\} z\_i = {\textbackslash}bar x - {\textbackslash}bar y. Consider the r=N!Nr = N! N-tuples obtained from (z1,⋯,zN)(z\_1, {\textbackslash}cdots, z\_N) by making all permutations of the indices (1,⋯,N)(1, {\textbackslash}cdots, N). Since we assume continuous cdf's, then with probability one, these rNr N-tuples will be distinct. Denote them by z(1),⋯,z(r)z{\textasciicircum}\{(1)\}, {\textbackslash}cdots, z{\textasciicircum}\{(r)\}, and suppose that they have been ordered so that u(z(1)≧⋯≧u(z(r))u(z{\textasciicircum}\{(1)\} {\textbackslash}geqq {\textbackslash}cdots {\textbackslash}geqq u(z{\textasciicircum}\{(r)\}). Notice that since ˉx−ˉy=(1/m)N∑i=1zi−(N/m)ˉy=(N/n)ˉx−(1/n)N∑i=1zi,{\textbackslash}bar x - {\textbackslash}bar y = (1/m) {\textbackslash}sum{\textasciicircum}N\_\{i = 1\} z\_i - (N/m){\textbackslash}bar y = (N/n){\textbackslash}bar x - (1/n) {\textbackslash}sum{\textasciicircum}N\_\{i = 1\} z\_i, the same ordering can be induced by choosing u(z)=cˉxu(z) = c{\textbackslash}bar x or u(z)=−cˉyu(z) = - c{\textbackslash}bar y for any c{\textgreater}0c {\textgreater} 0. Assuming that the cdf's of X1,Y1X\_1, Y\_1 are of the form F(x),F(x−Δ)F(x), F(x - {\textbackslash}Delta) respectively, Pitman [2] suggested essentially the following test of the hypothesis H′H' that Δ=0{\textbackslash}Delta = 0. Select a set of k(k{\textgreater}0)k (k {\textgreater} 0) integers i1,⋯,ik,(1≦i1{\textless}⋯{\textless}ik≦r)i\_1, {\textbackslash}cdots, i\_k, (1 {\textbackslash}leqq i\_1 {\textless} {\textbackslash}cdots {\textless} i\_k {\textbackslash}leqq r). If the observed zz is one of the points z(i1),⋯,z(ik)z{\textasciicircum}\{(i\_1)\}, {\textbackslash}cdots, z{\textasciicircum}\{(i\_k)\}, reject H′H', otherwise accept. When H′H' is true, the type one error does not depend on the specific form of the distribution of the XX's and the YY's and is in fact equal to k/rk/r. The choice of the rejection set i1,⋯,iki\_1, {\textbackslash}cdots, i\_k should depend on the alternative hypothesis. For instance, if the experimenter wants protection against the alternative that the "XX's tend to be larger than the YY's," then the labels 1,⋯,k1, {\textbackslash}cdots, k might be reasonable. For the alternative that the "XX's tend to be smaller than the YY's" the analogous procedure is to use the other tail, r−k+1,⋯,rr - k + 1, {\textbackslash}cdots, r. Against both alternatives, a two-tail procedure could be used. Lehmann and Stein have shown in [1] that in the class of all tests (of size α=k/r{\textbackslash}alpha = k/r) of the hypothesis H:the distribution ofX1⋯,Xm,Y1,⋯,Ynis invariant under all permutations,H: {\textbackslash}text\{the distribution of\} X\_1 {\textbackslash}cdots, X\_m, Y\_1, {\textbackslash}cdots, Y\_n {\textbackslash}text\{is invariant under all permutations\}, the single-tail test based on 1,⋯,k1, {\textbackslash}cdots, k is uniformly most powerful against the alternatives that F1F\_1 is an N(θ,σ)N({\textbackslash}theta, {\textbackslash}sigma) cdf, F2F\_2 is an N(θ+Δ,σ)N({\textbackslash}theta + {\textbackslash}Delta, {\textbackslash}sigma) cdf, Δ{\textless}0{\textbackslash}Delta {\textless} 0; the test based on r−k+1,⋯,rr - k + 1, {\textbackslash}cdots, r is uniformly most powerful for Δ{\textgreater}0{\textbackslash}Delta {\textgreater} 0. A practical shortcoming of this procedure is the great difficulty in enumerating the points z(i)z{\textasciicircum}\{(i)\} and the evaluation of u(z(i))u(z{\textasciicircum}\{(i)\}) for each of them. For instance, even after eliminating those permutations which always give the same value of uu, then for sample sizes m=n=5m = n = 5, there are (105)=252{\textbackslash}binom\{10\}\{5\} = 252 permutations to examine, and for sample sizes m=n=10m = n = 10, there are (2010)=184,765{\textbackslash}binom\{20\}\{10\} = 184,765 permutations to examine. In the following section, we propose the almost obvious procedure of examining a "random sample" of permutations and making the decision to accept or reject HH on the basis of those permutations only. Bounds are determined for the ratio of the power of the original procedure to the modified one. Some numerical values of these bounds are given in Table 1. The bounds there listed correspond to tests which in both original and modified form have size α{\textbackslash}alpha, and for which the modified test is based on a random sample of ss permutations drawn with replacement. These have been computed for a certain class of alternatives which is described below. For simplicity, we have restricted the main exposition to the two-sample problem. In Section 5, we point out extensions to the more general hypotheses of invariance studied in [1].},
	language = {EN},
	number = {1},
	urldate = {2016-07-29},
	journal = {The Annals of Mathematical Statistics},
	author = {Dwass, Meyer},
	month = mar,
	year = {1957},
	mrnumber = {MR87280},
	note = {bibtex: dwass\_modified\_1957},
	pages = {181--187},
	file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\29HM4EVJ\\1177707045.html:text/html}
}

@article{barnard_comment_1963,
	title = {Comment on: "{The} {Spectral} {Analysis} of {Point} {Processes}" by {M}.{S}. {Bartlett}},
	volume = {25},
	issn = {0035-9246},
	abstract = {The spectral analysis of stationary point processes in one dimension is developed in some detail as a statistical method of analysis. The asymptotic sampling theory previously established by the author for a class of doubly stochastic Poisson processes is shown to apply also for a class of clustering processes, the spectra of which are contrasted with those of renewal processes. The analysis is given for two illustrative examples, one an artificial Poisson process, the other of some traffic data. In addition to testing the fit of a clustering model to the latter example, the analysis of these two examples is used where possible to check the validity of the sampling theory.},
	number = {2},
	urldate = {2016-07-30},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Barnard, G. A.},
	year = {1963},
	note = {bibtex: barnard\_comment\_1963},
	pages = {294}
}

@book{wickham_scales:_2016,
	title = {scales: {Scale} {Functions} for {Visualization}},
	url = {https://CRAN.R-project.org/package=scales},
	author = {Wickham, Hadley},
	year = {2016},
	note = {R package version 0.4.0 
bibtex: wickham\_scales:\_2016}
}

@article{yang_xiang_generalized_2013,
	title = {Generalized {Simulated} {Annealing} for {Efficient} {Global} {Optimization}: the {GenSA} {Package} for {R}.},
	url = {http://journal.r-project.org/},
	journal = {The R Journal Volume 5/1, June 2013},
	author = {{Yang Xiang} and Gubian, Sylvain and Suomela, Brian and Hoeng, Julia},
	year = {2013},
	note = {bibtex: yang\_xiang\_generalized\_2013}
}

@book{bendtsen_pso:_2012,
	title = {pso: {Particle} {Swarm} {Optimization}},
	url = {https://CRAN.R-project.org/package=pso},
	author = {Bendtsen, Claus},
	year = {2012},
	note = {R package version 1.0.3 
bibtex: bendtsen\_pso:\_2012}
}

@book{gilli_numerical_2011,
	address = {Waltham, MA, USA},
	title = {Numerical {Methods} and {Optimization} in {Finance}},
	url = {http://nmof.net},
	publisher = {Academic Press},
	author = {Gilli, Manfred and Maringer, Dietmar and Schumann, Enrico},
	year = {2011},
	note = {bibtex: gilli\_numerical\_2011}
}

@article{dufour_exact_1996,
	title = {Exact tests for structural change in first-order dynamic models},
	volume = {70},
	issn = {0304-4076},
	url = {http://econpapers.repec.org/article/eeeeconom/v_3a70_3ay_3a1996_3ai_3a1_3ap_3a39-68.htm},
	number = {1},
	urldate = {2016-08-18},
	journal = {Journal of Econometrics},
	author = {Dufour, Jean-Marie and Kiviet, Jan},
	year = {1996},
	note = {bibtex: dufour\_exact\_1996},
	pages = {39--68},
	file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\Q6H7Q9FV\\v_3a70_3ay_3a1996_3ai_3a1_3ap_3a39-68.html:text/html}
}

@book{wickham_devtools:_2016,
	title = {devtools: {Tools} to make developing {R} code easier},
	author = {Wickham, Hadley and Chang, Winston},
	year = {2016},
	note = {R package version 1.5.0.99 
bibtex: wickham\_devtools:\_2016}
}

@article{dufour_rank-robust_2016,
	title = {Rank-robust {Wald}-type tests: a regularization approach},
	author = {Dufour, Jean-Marie and Valéry, Pascale},
	year = {2016},
	note = {bibtex: dufour\_rank-robust\_2016}
}

@techreport{boudjellaba_simplified_1992,
	type = {Cahiers de recherche},
	title = {Simplified {Conditions} for {Non}-{Causality} {Between} {Vectors} in {Multivariate} {Arma} {Models}},
	url = {https://ideas.repec.org/p/mtl/montde/9236.html},
	abstract = {No abstract is available for this item.},
	number = {9236},
	urldate = {2016-08-22},
	institution = {Universite de Montreal, Departement de sciences economiques},
	author = {Boudjellaba, H. and Dufour, J. M. and Roy, R.},
	year = {1992},
	note = {bibtex: boudjellaba\_simplified\_1992},
	keywords = {econometrics, ECONOMIC MODELS},
	file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\VJJNW7V7\\9236.html:text/html}
}

@incollection{gourieroux_size_2013,
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {Size {Distortion} in the {Analysis} of {Volatility} and {Covolatility} {Effects}},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-35442-7 978-3-642-35443-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-35443-4_7},
	abstract = {Let us assume that Â TA{\textasciicircum}T{\textbackslash}hat\{A\}\_T is a consistent, asymptotically normal estimator of a matrix A (where T is the sample size), this paper shows that test statistics used in empirical work to test 1) the noninvertibility of A, i.e. det A = 0, 2) the positivite semi-definiteness A {\textgreater} {\textgreater} 0, have a different asymptotic distribution in the case where A = 0 than in the case where A ≠ 0. Moreover, the paper shows that an estimator of A constrained by symmetry or reduced rank has a different asymptotic distribution when A = 0 than when A ≠ 0. The implication is that inference procedures that use critical values equal to appropriate quantiles from the distribution when A ≠ 0 may be size distorted. The paper points out how the above statistical problems arise in standard models in Finance in the analysis of risk effects.A Monte Carlo study explores how the asymptotic results are reflected in finite sample.},
	language = {en},
	number = {200},
	urldate = {2016-08-22},
	booktitle = {Uncertainty {Analysis} in {Econometrics} with {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Gourieroux, Christian and Jasiak, Joann},
	editor = {Huynh, Van-Nam and Kreinovich, Vladik and Sriboonchitta, Songsak and Suriya, Komsan},
	year = {2013},
	note = {DOI: 10.1007/978-3-642-35443-4\_7 
bibtex: gourieroux\_size\_2013},
	keywords = {Artificial Intelligence (incl. Robotics), BEKK Model, Boundary, C10, C32, Computational Intelligence, econometrics, G10, G12, Identifiability, Invertibility Test, Multivariate Volatility, Risk Premium, Volatility Transmission},
	pages = {91--118},
	file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\6XVKM8PJ\\10.html:text/html}
}

@article{boudjellaba_testing_1992,
	title = {Testing {Causality} {Between} {Two} {Vectors} in {Multivariate} {Autoregressive} {Moving} {Average} {Models}},
	volume = {87},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2290645},
	doi = {10.2307/2290645},
	abstract = {In the analysis of economic time series, a question often raised is whether a vector of variables causes another one in the sense of Granger. Most of the literature on this topic is concerned with bivariate relationships or uses finite-order autoregressive specifications. The purpose of this article is to develop a causality analysis in the sense of Granger for general vector autoregressive moving average (ARMA) models. We give a definition of Granger noncausality between vectors, which is a natural and simple extension of the notion of Granger noncausality between two variables. In our context, this definition is shown to be equivalent to a more complex definition proposed by Tjostheim. For the class of linear invertible processes, we derive a necessary and sufficient condition for noncausality between two vectors of variables when the latter do not necessarily include all the variables considered in the analysis. This result is then specialized to the class of stationary invertible ARMA processes. Further, relatively simple necessary and sufficient conditions are obtained for two important cases: (1) the case where the two vectors reduce to two variables inside a larger vector including other variables; and (2) the case where the two vectors embody all the variables considered. Test procedures for these necessary and sufficient conditions are discussed. Among other things, it is noted that the necessary and sufficient conditions for noncausality may involve singularities at which standard asymptotic regularity conditions do not hold. To deal with such situations, we propose a sequential approach that leads to bounds tests. Finally, the tests suggested are applied to Canadian money and income data. The tests are based on bivariate and trivariate models of changes in nominal income and two money stocks (M1 and M2). In contrast with the evidence based on bivariate models, we find from the trivariate model that money causes income unidirectionally.},
	number = {420},
	urldate = {2016-08-22},
	journal = {Journal of the American Statistical Association},
	author = {Boudjellaba, Hafida and Dufour, Jean-Marie and Roy, Roch},
	year = {1992},
	note = {bibtex: boudjellaba\_testing\_1992},
	pages = {1082--1090}
}

@article{mullen_continuous_2014,
	title = {Continuous global optimization in {R}},
	volume = {60},
	number = {6},
	journal = {Journal of Statistical Software},
	author = {Mullen, Katharine M and {others}},
	year = {2014},
	note = {bibtex: mullen\_continuous\_2014},
	pages = {1--45}
}

@article{scrucca_ga:_2013,
	title = {{GA}: {A} {Package} for {Genetic} {Algorithms} in {R}},
	volume = {53},
	url = {http://www.jstatsoft.org/v53/i04/},
	number = {4},
	journal = {Journal of Statistical Software},
	author = {Scrucca, Luca},
	year = {2013},
	note = {bibtex: scrucca\_ga:\_2013},
	pages = {1--37}
}

@article{scrucca_extensions_2016,
	title = {On some extensions to {GA} package: hybrid optimisation, parallelisation and islands evolution},
	url = {http://arxiv.org/abs/1605.01931},
	journal = {Submitted to R Journal},
	author = {Scrucca, Luca},
	year = {2016},
	note = {Pre-print available at arXiv 
bibtex: scrucca\_extensions\_2016}
}

@book{wuertz_funitroots:_2013,
	title = {{fUnitRoots}: {Trends} and {Unit} {Roots}},
	url = {https://CRAN.R-project.org/package=fUnitRoots},
	author = {Wuertz, Diethelm and {et al.}},
	year = {2013},
	note = {R package version 3010.78 
bibtex: wuertz\_funitroots:\_2013}
}

@book{mersmann_microbenchmark:_2015,
	title = {microbenchmark: {Accurate} {Timing} {Functions}},
	url = {https://CRAN.R-project.org/package=microbenchmark},
	author = {Mersmann, Olaf},
	year = {2015},
	note = {R package version 1.4-2.1 
bibtex: mersmann\_microbenchmark:\_2015}
}

@book{canty_boot:_2016,
	title = {boot: {Bootstrap} {R} ({S}-{Plus}) {Functions}},
	author = {Canty, Angelo and Ripley, B. D.},
	year = {2016},
	note = {R package version 1.3-18 
bibtex: canty\_boot:\_2016}
}

@book{davison_bootstrap_1997,
	address = {Cambridge},
	title = {Bootstrap {Methods} and {Their} {Applications}},
	url = {http://statwww.epfl.ch/davison/BMA/},
	publisher = {Cambridge University Press},
	author = {Davison, A. C. and Hinkley, D. V.},
	year = {1997},
	note = {ISBN 0-521-57391-2 
bibtex: davison\_bootstrap\_1997}
}

@book{geyer_mcmc:_2015,
	title = {mcmc: {Markov} {Chain} {Monte} {Carlo}},
	url = {https://CRAN.R-project.org/package=mcmc},
	author = {Geyer, Charles J. and Johnson, Leif T.},
	year = {2015},
	note = {R package version 0.9-4 
bibtex: geyer\_mcmc:\_2015}
}

@article{martin_mcmcpack:_2011,
	title = {{MCMCpack}: {Markov} {Chain} {Monte} {Carlo} in {R}},
	volume = {42},
	url = {http://www.jstatsoft.org/v42/i09/},
	number = {9},
	journal = {Journal of Statistical Software},
	author = {Martin, Andrew D. and Quinn, Kevin M. and Park, Jong Hee},
	year = {2011},
	note = {bibtex: martin\_mcmcpack:\_2011},
	pages = {22}
}

@book{bornn_pawl:_2012,
	title = {{PAWL}: {Implementation} of the {PAWL} algorithm},
	url = {https://CRAN.R-project.org/package=PAWL},
	author = {Bornn, Luke and Jacob, Pierre E.},
	year = {2012},
	note = {R package version 0.5 
bibtex: bornn\_pawl:\_2012}
}

@article{fernandez-i-marin_ggmcmc:_2016,
	title = {ggmcmc: {Analysis} of {MCMC} {Samples} and {Bayesian} {Inference}},
	volume = {70},
	doi = {10.18637/jss.v070.i09},
	number = {9},
	journal = {Journal of Statistical Software},
	author = {Fernández-i-Marín, Xavier},
	year = {2016},
	note = {bibtex: fernandez-i-marin\_ggmcmc:\_2016},
	pages = {1--20}
}

@book{caffo_exactloglintest:_2013,
	title = {{exactLoglinTest}: {Monte} {Carlo} {Exact} {Tests} for {Log}-linear models},
	url = {https://CRAN.R-project.org/package=exactLoglinTest},
	author = {Caffo, Brian},
	year = {2013},
	note = {R package version 1.4.2 
bibtex: caffo\_exactloglintest:\_2013}
}

@book{r_core_team_r:_2016,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2016},
	note = {bibtex: r\_core\_team\_r:\_2016}
}

@article{zambrano-bigiarini_model-independent_2013,
	title = {A model-independent {Particle} {Swarm} {Optimisation} software for model calibration},
	volume = {43},
	url = {http://dx.doi.org/10.1016/j.envsoft.2013.01.004},
	journal = {Environmental Modelling  Software},
	author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
	year = {2013},
	note = {bibtex: zambrano-bigiarini\_model-independent\_2013},
	pages = {5--25}
}

@book{zambrano-bigiarini_hydropso:_2014,
	title = {{hydroPSO}: {Particle} {Swarm} {Optimisation}, with focus on {Environmental} {Models}},
	url = {http://www.rforge.net/hydroPSO, http://cran.r-project.org/web/packages/hydroPSO},
	author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
	year = {2014},
	note = {R package version 0.3-4}
}

@book{ardia_deoptim:_2015,
	title = {{DEoptim}: {Differential} {Evolution} in {R}},
	url = {http://CRAN.R-project.org/package=DEoptim},
	author = {Ardia, David and Mullen, Katharine M. and Peterson, Brian G. and Ulrich, Joshua},
	year = {2015},
	note = {version 2.2-3 
 = \{\{DEoptim\}: Differential Evolution in \{R\}\} 
bibtex: ardia\_deoptim:\_2015}
}

@article{mullen_deoptim:_2011,
	title = {{DEoptim}: {An} {R} {Package} for {Global} {Optimization} by {Differential} {Evolution}},
	volume = {40},
	url = {http://www.jstatsoft.org/v40/i06/},
	number = {6},
	journal = {Journal of Statistical Software},
	author = {Mullen, Katharine and Ardia, David and Gil, David and Windover, Donald and Cline, James},
	year = {2011},
	note = {= \{\{DEoptim\}: An \{R\} Package for Global Optimization by Differential Evolution\} 
bibtex: mullen\_deoptim:\_2011},
	pages = {1--26}
}

@article{ardia_differential_2011,
	title = {Differential {Evolution} with {DEoptim}: {An} {Application} to {Non}-{Convex} {Portfolio} {Optimization}},
	volume = {3},
	url = {http://journal.r-project.org/archive/2011-1/2011-1_index.html},
	number = {1},
	journal = {The R Journal},
	author = {Ardia, David and Boudt, Kris and Carl, Peter and Mullen, Katharine M. and Peterson, Brian G.},
	year = {2011},
	note = {= \{\{D\}ifferential \{E\}volution with \{DEoptim\}: An Application to Non-Convex Portfolio Optimization\} 
bibtex: ardia\_differential\_2011},
	pages = {27--34}
}

@article{ardia_jump-diffusion_2011,
	title = {Jump-{Diffusion} {Calibration} using {Differential} {Evolution}},
	volume = {55},
	url = {http://www.wilmott.com/},
	journal = {Wilmott Magazine},
	author = {Ardia, David and Arango, Juan Ospina and Gomez, Norman Giraldo},
	year = {2011},
	note = {= \{\{J\}ump-Diffusion Calibration using \{D\}ifferential \{E\}volution\} 
bibtex: ardia\_jump-diffusion\_2011},
	pages = {76--79}
}

@book{price_differential_2006,
	series = {Natural {Computing}},
	title = {Differential {Evolution} - {A} {Practical} {Approach} to {Global} {Optimization}},
	publisher = {Springer-Verlag},
	author = {Price, Kenneth V. and Storn, Rainer M. and Lampinen, Jouni A.},
	month = jan,
	year = {2006},
	note = {ISBN 540209506}
}

@book{clayden_soma:_2014,
	title = {soma: {General}-{Purpose} {Optimisation} {With} the {Self}-{Organising} {Migrating} {Algorithm}},
	url = {https://CRAN.R-project.org/package=soma},
	author = {Clayden, Jon and Zelinka, Ivan},
	year = {2014},
	note = {R package version 1.1.1}
}

@book{bergmeir_continuous_2012,
	title = {Continuous {Optimization} using {Memetic} {Algorithms} with {Local} {Search} {Chains} ({MA}-{LS}-{Chains}) in {R}},
	author = {Bergmeir, Christoph and Molina, Daniel and Beńitez, Jośe M.},
	year = {2012},
	note = {R package version 0.1 
 = \{Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R\} 
bibtex: bergmeir\_continuous\_2012}
}

@book{trautmann_cmaes:_2011,
	title = {cmaes: {Covariance} {Matrix} {Adapting} {Evolutionary} {Strategy}},
	url = {https://CRAN.R-project.org/package=cmaes},
	author = {Trautmann, Heike and Mersmann, Olaf and Arnu, David},
	year = {2011},
	note = {R package version 1.0-11 
 = \{cmaes: Covariance Matrix Adapting Evolutionary Strategy\} 
bibtex: trautmann\_cmaes:\_2011}
}

@book{ghalanos_parma:_2015,
	title = {parma: portfolio allocation and risk management applications},
	author = {Ghalanos, Alexios and Pfaff, Bernhard},
	year = {2015},
	note = {R package version 1.5-2. 
 = \{parma: portfolio allocation and risk management applications.\} 
bibtex: ghalanos\_parma:\_2015}
}

@book{burns_burstmisc:_2016,
	title = {{BurStMisc}: {Burns} {Statistics} {Miscellaneous}},
	url = {https://CRAN.R-project.org/package=BurStMisc},
	author = {Burns, Pat},
	year = {2016},
	note = {R package version 1.1 
 = \{BurStMisc: Burns Statistics Miscellaneous\} 
bibtex: burns\_burstmisc:\_2016}
}

@article{satman_machine_2013,
	title = {Machine {Coded} {Genetic} {Algorithms} {For} {Real} {Parameter} {Optimization} {Problems}},
	volume = {26},
	url = {http://gujs.gazi.edu.tr/article/view/1060000982},
	number = {1},
	journal = {Gazi University Journal of Science},
	author = {Satman, Mehmet Hakan},
	year = {2013},
	note = {= \{Machine Coded Genetic Algorithms For Real Parameter Optimization Problems\} 
bibtex: satman\_machine\_2013},
	pages = {85--95}
}

@book{ciupke_psoptim:_2016,
	title = {psoptim: {Particle} {Swarm} {Optimization}},
	url = {https://CRAN.R-project.org/package=psoptim},
	author = {Ciupke, Krzysztof},
	year = {2016},
	note = {R package version 1.0 
 = \{psoptim: Particle Swarm Optimization\} 
bibtex: ciupke\_psoptim:\_2016}
}

@article{fisher_fiducial_1935,
	title = {The fiducial argument in statistical inference},
	doi = {10.1111/j.1469-1809.1935.tb02120.x},
	journal = {Annals of Eugenics.},
	author = {Fisher, R. A.},
	year = {1935},
	note = {bibtex: fisher\_fiducial\_1935},
	pages = {391--398}
}

@article{fisher_asymptotic_1941,
	title = {The asymptotic approach to {Behrens}' integral, with further tables for the d test of significance},
	volume = {11},
	doi = {10.1111/j.1469-1809.1941.tb02281.x},
	journal = {Annals of Eugenics.},
	author = {Fisher, R. A.},
	year = {1941},
	note = {bibtex: fisher\_asymptotic\_1941},
	pages = {141--172}
}

@article{behrens_beitrag_1929,
	title = {Ein {Beitrag} zur {Fehlerberechnung} bei wenigen {Beobachtungen}},
	volume = {68},
	journal = {Landwirtschaftliche Jahrbucher.},
	author = {Behrens, W. U.},
	year = {1929},
	note = {bibtex: behrens\_beitrag\_1929},
	pages = {807--837}
}

@article{welch_significance_1938,
	title = {The significance or the difference between two means when the population variances are unequal},
	volume = {29},
	doi = {10.2307/2332010},
	journal = {Biometrika.},
	author = {Welch, B. L.},
	year = {1938},
	note = {bibtex: welch\_significance\_1938},
	pages = {350--362}
}

@article{welch_generalization_1947,
	title = {The generalization of '{Student}'s' problem when several different population variances are involved},
	volume = {34},
	doi = {10.2307/2332510},
	journal = {Biometrika.},
	author = {Welch, B. L.},
	year = {1947},
	note = {bibtex: welch\_generalization\_1947},
	pages = {28--35}
}

@inproceedings{eberhart_new_1995,
	title = {A new optimizer using particle swarm theory},
	volume = {1},
	booktitle = {Proceedings of the sixth international symposium on micro machine and human science},
	publisher = {New York, NY},
	author = {Eberhart, Russ C and Kennedy, James and {others}},
	year = {1995},
	note = {bibtex: eberhart\_new\_1995},
	pages = {39--43}
}

@article{kirkpatrick_optimization_1984,
	title = {Optimization by simulated annealing: {Quantitative} studies},
	volume = {34},
	number = {5-6},
	journal = {Journal of statistical physics},
	author = {Kirkpatrick, Scott},
	year = {1984},
	note = {bibtex: kirkpatrick\_optimization\_1984},
	pages = {975--986}
}

@article{holland_adaptation_1992,
	title = {Adaptation in natural and artificial systems. 1975},
	journal = {Ann Arbor, MI: University of Michigan Press and},
	author = {Holland, John H},
	year = {1992},
	note = {bibtex: holland\_adaptation\_1992}
}

@article{dufour_exact_2001,
	title = {Exact {Nonparametric} {Two}-{Sample} {Homogeneity} {Tests} for {Possibly} {Discrete} {Distributions}.},
	author = {Dufour, Jean-Marie and Farhat, Abdeljelil},
	year = {2001},
	note = {bibtex: dufour\_exact\_2001}
}

@article{david_a._dickey_determining_1987,
	title = {Determining the {Order} of {Differencing} in {Autoregressive} {Processes}},
	volume = {5},
	issn = {07350015},
	url = {http://www.jstor.org/stable/1391997},
	abstract = {One way of handling nonstationarity in time series is to compute first differences and fit a model to the differenced series unless the differenced series also looks nonstationary. In that case, second- or higher-order differencing is done. To decide if the current degree of differencing is sufficient, one can look at the autocorrelation function for slow decay. A formal statistical test for the need to difference further is available if one is willing to assume that at most one more difference will render the series stationary. In this article, we present a proper sequence of statistical tests that allows the practitioner to handle cases in which a high order of differencing may be needed. The proper sequence is not the traditional sequence, which begins with a test for a single unit root.},
	number = {4},
	journal = {Journal of Business  Economic Statistics},
	author = {David A. Dickey, Sastry G. Pantula},
	year = {1987},
	note = {bibtex: david\_a.\_dickey\_determining\_1987},
	pages = {455--461}
}

@article{pantula_testing_1989,
	title = {Testing for {Unit} {Roots} in {Time} {Series} {Data}},
	volume = {5},
	issn = {02664666, 14694360},
	url = {http://www.jstor.org/stable/3532498},
	abstract = {Let Yt satisfy the stochastic difference equation Yt=Σ j=1 pα jYt-j+Σ j=1 qθ jet-j+et, for t = 1,2,..., where et are independent and identically distributed random variables with mean zero and variance σ 2 and the initial conditions (Y-p+1,...,Y0) are fixed constants. It is assumed that the process is invertible and that the true, but unknown, roots m1,m2,...,mp of mp-Σ j=1 pα jmp-j=0 satisfy the hypothesis Hd: m1=...=md=1 and {\textbar}m$_{\textrm{j}}${\textbar}{\textless}1 for j = d + 1,...,p. We present a reparameterization of the model for Yt that is convenient for testing the hypothesis Hd. We consider the asymptotic properties of (i) a likelihood ratio type "F-statistic" for testing the hypothesis Hd, (ii) a likelihood ratio type t-statistic for testing the hypothesis Hd against the alternative Hd-1. Using these asymptotic results, we obtain two sequential testing procedures that are asymptotically consistent.},
	number = {2},
	journal = {Econometric Theory},
	author = {Pantula, Sastry G.},
	year = {1989},
	note = {bibtex: pantula\_testing\_1989},
	pages = {256--271}
}

@book{fuller_introduction_1976,
	address = {New York, NY},
	title = {Introduction to {Statistical} {Time} {Series}},
	publisher = {John Wiley},
	author = {Fuller, W. A.},
	year = {1976},
	note = {bibtex: fuller\_introduction\_1976}
}

@article{cerny_thermodynamical_1985,
	title = {Thermodynamical approach to the traveling salesman problem: {An} efficient simulation algorithm},
	volume = {45},
	issn = {0022-3239, 1573-2878},
	shorttitle = {Thermodynamical approach to the traveling salesman problem},
	url = {http://link.springer.com/article/10.1007/BF00940812},
	doi = {10.1007/BF00940812},
	abstract = {We present a Monte Carlo algorithm to find approximate solutions of the traveling salesman problem. The algorithm generates randomly the permutations of the stations of the traveling salesman trip, with probability depending on the length of the corresponding route. Reasoning by analogy with statistical thermodynamics, we use the probability given by the Boltzmann-Gibbs distribution. Surprisingly enough, using this simple algorithm, one can get very close to the optimal solution of the problem or even find the true optimum. We demonstrate this on several examples.We conjecture that the analogy with thermodynamics can offer a new insight into optimization problems and can suggest efficient algorithms for solving them.},
	language = {en},
	number = {1},
	urldate = {2016-08-26},
	journal = {Journal of Optimization Theory and Applications},
	author = {Černý, V.},
	year = {1985},
	note = {bibtex: cerny\_thermodynamical\_1985},
	pages = {41--51},
	file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\78AP9FFF\\10.html:text/html}
}

@article{kirkpatrick_optimization_1983,
	title = {Optimization by simulated annealing},
	volume = {220},
	issn = {0036-8075},
	doi = {10.1126/science.220.4598.671},
	abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
	language = {eng},
	number = {4598},
	journal = {Science (New York, N.Y.)},
	author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
	month = may,
	year = {1983},
	pmid = {17813860},
	note = {bibtex: kirkpatrick\_optimization\_1983},
	pages = {671--680}
}

@inproceedings{shi_modified_1998,
	title = {A modified particle swarm optimizer},
	booktitle = {Evolutionary {Computation} {Proceedings}, 1998. {IEEE} {World} {Congress} on {Computational} {Intelligence}., {The} 1998 {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Shi, Yuhui and Eberhart, Russell},
	year = {1998},
	note = {bibtex: shi\_modified\_1998},
	pages = {69--73}
}

@book{willighagen_genalg:_2015,
	title = {genalg: {R} {Based} {Genetic} {Algorithm}},
	url = {https://CRAN.R-project.org/package=genalg},
	author = {Willighagen, Egon and Ballings, Michel},
	year = {2015},
	note = {R package version 0.2.0 
bibtex: willighagen\_genalg:\_2015}
}

@book{wickham_ggplot2:_2009,
	title = {ggplot2: {Elegant} {Graphics} for {Data} {Analysis}},
	isbn = {978-0-387-98140-6},
	url = {http://ggplot2.org},
	publisher = {Springer-Verlag New York},
	author = {Wickham, Hadley},
	year = {2009},
	note = {bibtex: wickham\_ggplot2:\_2009}
}

@techreport{banerjee_co-integration_1993,
	type = {{OUP} {Catalogue}},
	title = {Co-integration, {Error} {Correction}, and the {Econometric} {Analysis} of {Non}-{Stationary} {Data}},
	url = {http://econpapers.repec.org/bookchap/oxpobooks/9780198288107.htm},
	abstract = {This book provides a wide-ranging account of the literature on co-integration and the modelling of integrated processes (those which accumulate the effects of past shocks). Data series which display integrated behaviour are common in economics, although techniques appropriate to analysing such data are of recent origin and there are few existing expositions of the literature. This book focuses on the exploration of relationships among integrated data series and the exploitation of these relationships in dynamic econometric modelling. The concepts of co-integration and error-correction models are fundamental components of the modelling strategy. This area of time-series econometrics has grown in importance over the past decade and is of interest to econometric theorists and applied econometricians alike. By explaining the important concepts informally, but also presenting them formally, the book bridges the gap between purely descriptive and purely theoretical accounts of the literature. The asymptotic theory of integrated processes is described and the tools provided by this theory are used to develop the distributions of estimators and test statistics. Practical modelling advice, and the use of techniques for systems estimation, are also emphasized. A knowledge of econometrics, statistics, and matrix algebra at the level of a final-year undergraduate or first-year undergraduate course in econometrics is sufficient for most of the book. Other mathematical tools are described as they occur.},
	urldate = {2016-08-27},
	institution = {Oxford University Press},
	author = {Banerjee, Anindya and Dolado, Juan and Galbraith, John and Hendry, David},
	year = {1993},
	note = {bibtex: banerjee\_co-integration\_1993},
	file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\BW99JKBE\\9780198288107.html:text/html}
}

@book{zeileis_dynlm:_2014,
	title = {dynlm: {Dynamic} {Linear} {Regression}},
	url = {http://CRAN.R-project.org/package=dynlm},
	author = {Zeileis, Achim},
	year = {2014},
	note = {R package version 0.3-3 
bibtex: zeileis\_dynlm:\_2014}
}

@article{dickey_distribution_1979,
	title = {Distribution of the {Estimators} for {Autoregressive} {Time} {Series} {With} a {Unit} {Root}},
	volume = {74},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2286348},
	doi = {10.2307/2286348},
	abstract = {Let n observations Y$_{\textrm{1}}$, Y$_{\textrm{2}}$, ..., Y$_{\textrm{n}}$ be generated by the model Y$_{\textrm{t}}$ = ρ Y$_{\textrm{t - 1}}$ + e$_{\textrm{t}}$, where Y$_{\textrm{0}}$ is a fixed constant and \{e$_{\textrm{t}}$\}$_{\textrm{t = 1}}$$^{\textrm{n}}$ is a sequence of independent normal random variables with mean 0 and variance σ$^{\textrm{2}}$. Properties of the regression estimator of ρ are obtained under the assumption that ρ = ± 1. Representations for the limit distributions of the estimator of ρ and of the regression t test are derived. The estimator of ρ and the regression t test furnish methods of testing the hypothesis that ρ = 1.},
	number = {366},
	urldate = {2016-08-28},
	journal = {Journal of the American Statistical Association},
	author = {Dickey, David A. and Fuller, Wayne A.},
	year = {1979},
	pages = {427--431}
}

@article{smirnov_table_1948,
	title = {Table for estimating the goodness of fit of empirical distributions},
	volume = {19},
	number = {2},
	journal = {The annals of mathematical statistics},
	author = {Smirnov, Nickolay},
	year = {1948},
	note = {bibtex: smirnov\_table\_1948},
	pages = {279--281}
}

@article{smirnoff_sur_1939,
	title = {Sur les écarts de la courbe de distribution empirique},
	volume = {48},
	number = {1},
	journal = {Matematicheskii Sbornik},
	author = {Smirnoff, N},
	year = {1939},
	note = {bibtex: smirnoff\_sur\_1939},
	pages = {3--26}
}

@book{venables_modern_2002,
	address = {New York},
	edition = {Fourth},
	title = {Modern {Applied} {Statistics} with {S}},
	url = {http://www.stats.ox.ac.uk/pub/MASS4},
	publisher = {Springer},
	author = {Venables, W. N. and Ripley, B. D.},
	year = {2002},
	note = {ISBN 0-387-95457-0 
bibtex: venables\_modern\_2002}
}

@book{wickham_roxygen2:_2015,
	title = {roxygen2: {In}-{Source} {Documentation} for {R}},
	url = {https://CRAN.R-project.org/package=roxygen2},
	author = {Wickham, Hadley and Danenberg, Peter and Eugster, Manuel},
	year = {2015},
	note = {R package version 5.0.1 
bibtex: wickham\_roxygen2:\_2015}
}
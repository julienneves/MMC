@article{satman_machine_2013,
author = {Satman, Mehmet Hakan},
number = {1},
pages = {85--95},
title = {{Machine Coded Genetic Algorithms For Real Parameter Optimization Problems}},
url = {http://gujs.gazi.edu.tr/article/view/1060000982},
volume = {26}
}
@article{ardia_differential_2011,
author = {Ardia, David and Boudt, Kris and Carl, Peter and Mullen, Katharine M and Peterson, Brian G},
number = {1},
pages = {27--34},
title = {{Differential Evolution with {\{}DEoptim{\}}: An Application to Non-Convex Portfolio Optimization}},
url = {http://journal.r-project.org/archive/2011-1/2011-1{\_}index.html},
volume = {3}
}
@article{smirnov_table_1948,
author = {Smirnov, Nickolay},
number = {2},
pages = {279--281},
title = {{Table for estimating the goodness of fit of empirical distributions}},
volume = {19}
}
@article{holland_adaptation_1992,
author = {Holland, John H},
title = {{Adaptation in natural and artificial systems. 1975}}
}
@book{ghalanos_parma:_2015,
author = {Ghalanos, Alexios and Pfaff, Bernhard},
title = {parma: portfolio allocation and risk management applications}
}
@article{boudjellaba_testing_1992,
abstract = {In the analysis of economic time series, a question often raised is whether a vector of variables causes another one in the sense of Granger. Most of the literature on this topic is concerned with bivariate relationships or uses finite-order autoregressive specifications. The purpose of this article is to develop a causality analysis in the sense of Granger for general vector autoregressive moving average ({\{}ARMA{\}}) models. We give a definition of Granger noncausality between vectors, which is a natural and simple extension of the notion of Granger noncausality between two variables. In our context, this definition is shown to be equivalent to a more complex definition proposed by Tjostheim. For the class of linear invertible processes, we derive a necessary and sufficient condition for noncausality between two vectors of variables when the latter do not necessarily include all the variables considered in the analysis. This result is then specialized to the class of stationary invertible {\{}ARMA{\}} processes. Further, relatively simple necessary and sufficient conditions are obtained for two important cases: (1) the case where the two vectors reduce to two variables inside a larger vector including other variables; and (2) the case where the two vectors embody all the variables considered. Test procedures for these necessary and sufficient conditions are discussed. Among other things, it is noted that the necessary and sufficient conditions for noncausality may involve singularities at which standard asymptotic regularity conditions do not hold. To deal with such situations, we propose a sequential approach that leads to bounds tests. Finally, the tests suggested are applied to Canadian money and income data. The tests are based on bivariate and trivariate models of changes in nominal income and two money stocks (M1 and M2). In contrast with the evidence based on bivariate models, we find from the trivariate model that money causes income unidirectionally.},
author = {Boudjellaba, Hafida and Dufour, Jean-Marie and Roy, Roch},
doi = {10.2307/2290645},
issn = {0162-1459},
number = {420},
pages = {1082--1090},
title = {{Testing Causality Between Two Vectors in Multivariate Autoregressive Moving Average Models}},
url = {http://www.jstor.org/stable/2290645},
volume = {87}
}
@book{burns_burstmisc:_2016,
author = {Burns, Pat},
title = {{{\{}BurStMisc{\}}: Burns Statistics Miscellaneous}},
url = {https://cran.r-project.org/package=BurStMisc}
}
@book{wickham_scales:_2016,
author = {Wickham, Hadley},
title = {{scales: Scale Functions for Visualization}},
url = {https://cran.r-project.org/package=scales}
}
@misc{banerjee_co-integration_1993,
abstract = {This book provides a wide-ranging account of the literature on co-integration and the modelling of integrated processes (those which accumulate the effects of past shocks). Data series which display integrated behaviour are common in economics, although techniques appropriate to analysing such data are of recent origin and there are few existing expositions of the literature. This book focuses on the exploration of relationships among integrated data series and the exploitation of these relationships in dynamic econometric modelling. The concepts of co-integration and error-correction models are fundamental components of the modelling strategy. This area of time-series econometrics has grown in importance over the past decade and is of interest to econometric theorists and applied econometricians alike. By explaining the important concepts informally, but also presenting them formally, the book bridges the gap between purely descriptive and purely theoretical accounts of the literature. The asymptotic theory of integrated processes is described and the tools provided by this theory are used to develop the distributions of estimators and test statistics. Practical modelling advice, and the use of techniques for systems estimation, are also emphasized. A knowledge of econometrics, statistics, and matrix algebra at the level of a final-year undergraduate or first-year undergraduate course in econometrics is sufficient for most of the book. Other mathematical tools are described as they occur.},
author = {Banerjee, Anindya and Dolado, Juan and Galbraith, John and Hendry, David},
institution = {Oxford University Press},
title = {{Co-integration, Error Correction, and the Econometric Analysis of Non-Stationary Data}},
type = {{\{}OUP{\}} Catalogue},
url = {http://econpapers.repec.org/bookchap/oxpobooks/9780198288107.htm}
}
@article{mullen_deoptim:_2011,
author = {Mullen, Katharine and Ardia, David and Gil, David and Windover, Donald and Cline, James},
number = {6},
pages = {1--26},
title = {{{\{}DEoptim{\}}: An R Package for Global Optimization by Differential Evolution}},
url = {http://www.jstatsoft.org/v40/i06/},
volume = {40}
}
@article{david_a._dickey_determining_1987,
abstract = {One way of handling nonstationarity in time series is to compute first differences and fit a model to the differenced series unless the differenced series also looks nonstationary. In that case, second- or higher-order differencing is done. To decide if the current degree of differencing is sufficient, one can look at the autocorrelation function for slow decay. A formal statistical test for the need to difference further is available if one is willing to assume that at most one more difference will render the series stationary. In this article, we present a proper sequence of statistical tests that allows the practitioner to handle cases in which a high order of differencing may be needed. The proper sequence is not the traditional sequence, which begins with a test for a single unit root.},
author = {{David A. Dickey}, Sastry G Pantula},
issn = {07350015},
number = {4},
pages = {455--461},
title = {{Determining the Order of Differencing in Autoregressive Processes}},
url = {http://www.jstor.org/stable/1391997},
volume = {5}
}
@article{dufour_exact_1996,
author = {Dufour, Jean-Marie and Kiviet, Jan},
issn = {0304-4076},
number = {1},
pages = {39--68},
title = {{Exact tests for structural change in first-order dynamic models}},
url = {http://econpapers.repec.org/article/eeeeconom/v{\_}3a70{\_}3ay{\_}3a1996{\_}3ai{\_}3a1{\_}3ap{\_}3a39-68.htm},
volume = {70}
}
@article{ardia_jump-diffusion_2011,
author = {Ardia, David and Arango, Juan Ospina and Gomez, Norman Giraldo},
pages = {76--79},
title = {{Jump-Diffusion Calibration using Differential Evolution}},
url = {http://www.wilmott.com/},
volume = {55}
}
@article{fisher_fiducial_1935,
author = {Fisher, R A},
doi = {10.1111/j.1469-1809.1935.tb02120.x},
pages = {391--398},
title = {{The fiducial argument in statistical inference}}
}
@incollection{dufour_monte_2003,
abstract = {This chapter contains section titled:

* {\{}INTRODUCTION{\}}
* {\{}STATISTICAL{\}} {\{}ISSUES{\}}: A {\{}PRACTICAL{\}} {\{}APPROACH{\}} {\{}TO{\}} {\{}CORE{\}} {\{}QUESTIONS{\}}
* {\{}THE{\}} {\{}MONTE{\}} {\{}CARLO{\}} {\{}TEST{\}} {\{}TECHNIQUE{\}}: {\{}AN{\}} {\{}EXACT{\}} {\{}RANDOMIZED{\}} {\{}TEST{\}} {\{}PROCEDURE{\}} * {\{}MONTE{\}} {\{}CARLO{\}} {\{}TESTS{\}}: {\{}ECONOMETRIC{\}} {\{}APPLICATIONS{\}}
* {\{}CONCLUSION{\}}},
author = {Dufour, Jean-Marie and Khalaf, Lynda},
booktitle = {A Companion to Theoretical Econometrics},
editor = {Baltagi, Badi H},
isbn = {978-0-470-99624-9},
keywords = {Monte Carlo test methods,econometrics,multivariate regression models,nuisance parameters,randomized test procedure},
pages = {494--519},
publisher = {Blackwell Publishing Ltd},
title = {{Monte Carlo Test Methods in Econometrics}}
}
@article{dickey_distribution_1979,
abstract = {Let n observations Y{\$}{\_}{\{}\backslashtextrm{\{}1{\}}{\}}{\$}, Y{\$}{\_}{\{}\backslashtextrm{\{}2{\}}{\}}{\$}, ..., Y{\$}{\_}{\{}\backslashtextrm{\{}n{\}}{\}}{\$} be generated by the model Y{\$}{\_}{\{}\backslashtextrm{\{}t{\}}{\}}{\$} = $\rho$ Y{\$}{\_}{\{}\backslashtextrm{\{}t - 1{\}}{\}}{\$} + e{\$}{\_}{\{}\backslashtextrm{\{}t{\}}{\}}{\$}, where Y{\$}{\_}{\{}\backslashtextrm{\{}0{\}}{\}}{\$} is a fixed constant and {\{}e{\$}{\_}{\{}\backslashtextrm{\{}t{\}}{\}}{\$}{\}}{\$}{\_}{\{}\backslashtextrm{\{}t = 1{\}}{\}}{\$}{\$}{\^{}}{\{}\backslashtextrm{\{}n{\}}{\}}{\$} is a sequence of independent normal random variables with mean 0 and variance $\sigma${\$}{\^{}}{\{}\backslashtextrm{\{}2{\}}{\}}{\$}. Properties of the regression estimator of $\rho$ are obtained under the assumption that $\rho$ = Â± 1. Representations for the limit distributions of the estimator of $\rho$ and of the regression t test are derived. The estimator of $\rho$ and the regression t test furnish methods of testing the hypothesis that $\rho$ = 1.},
author = {Dickey, David A and Fuller, Wayne A},
doi = {10.2307/2286348},
issn = {0162-1459},
number = {366},
pages = {427--431},
title = {{Distribution of the Estimators for Autoregressive Time Series With a Unit Root}},
url = {http://www.jstor.org/stable/2286348},
volume = {74}
}
@article{welch_significance_1938,
author = {Welch, B L},
doi = {10.2307/2332010},
pages = {350--362},
title = {{The significance or the difference between two means when the population variances are unequal}},
volume = {29}
}
@inproceedings{eberhart_new_1995,
author = {Eberhart, Russ C and Kennedy, James and Others},
booktitle = {Proceedings of the sixth international symposium on micro machine and human science},
pages = {39--43},
publisher = {New York, {\{}NY{\}}},
title = {{A new optimizer using particle swarm theory}},
volume = {1}
}
@book{ardia_deoptim:_2015,
author = {Ardia, David and Mullen, Katharine M and Peterson, Brian G and Ulrich, Joshua},
title = {{{\{}DEoptim{\}}: Differential Evolution in R}},
url = {http://cran.r-project.org/package=DEoptim}
}
@article{scrucca_extensions_2016,
author = {Scrucca, Luca},
title = {{On some extensions to {\{}GA{\}} package: hybrid optimisation, parallelisation and islands evolution}},
url = {http://arxiv.org/abs/1605.01931}
}
@article{barnard_comment_1963,
abstract = {The spectral analysis of stationary point processes in one dimension is developed in some detail as a statistical method of analysis. The asymptotic sampling theory previously established by the author for a class of doubly stochastic Poisson processes is shown to apply also for a class of clustering processes, the spectra of which are contrasted with those of renewal processes. The analysis is given for two illustrative examples, one an artificial Poisson process, the other of some traffic data. In addition to testing the fit of a clustering model to the latter example, the analysis of these two examples is used where possible to check the validity of the sampling theory.},
author = {Barnard, G A},
issn = {0035-9246},
number = {2},
pages = {294},
title = {{Comment on: "The Spectral Analysis of Point Processes" by M.S. Bartlett}},
volume = {25}
}
@book{wickham_roxygen2:_2015,
author = {Wickham, Hadley and Danenberg, Peter and Eugster, Manuel},
title = {{roxygen2: In-Source Documentation for R}},
url = {https://cran.r-project.org/package=roxygen2}
}
@book{zeileis_dynlm:_2014,
author = {Zeileis, Achim},
title = {{dynlm: Dynamic Linear Regression}},
url = {http://cran.r-project.org/package=dynlm}
}
@book{fuller_introduction_1976,
author = {Fuller, W A},
publisher = {John Wiley},
title = {{Introduction to Statistical Time Series}}
}
@article{fisher_asymptotic_1941,
author = {Fisher, R A},
doi = {10.1111/j.1469-1809.1941.tb02281.x},
pages = {141--172},
title = {{The asymptotic approach to Behrens' integral, with further tables for the d test of significance}},
volume = {11}
}
@book{bornn_pawl:_2012,
author = {Bornn, Luke and Jacob, Pierre E},
title = {{{\{}PAWL{\}}: Implementation of the {\{}PAWL{\}} algorithm}},
url = {https://cran.r-project.org/package=PAWL}
}
@article{dwass_modified_1957,
abstract = {Suppose X1,â¯,Xm,Y1,â¯,{\{}YnX{\}}{\_}1, {\{}$\backslash$textbackslash{\}}cdots, X{\_}m, Y{\_}1, {\{}$\backslash$textbackslash{\}}cdots, Y{\_}n are m+n=Nm + n = N independent random variables, the {\{}XX{\}}'s identically distributed and the {\{}YY{\}}'s identically distributed, each with a continuous cdf. Let z=(z1,â¯,zm,zm+1,â¯,{\{}zN{\}})=(x1,â¯,xm,y1,â¯,yn)z = (z{\_}1, {\{}$\backslash$textbackslash{\}}cdots, z{\_}m, z{\_}{\{}m + 1{\}}, {\{}$\backslash$textbackslash{\}}cdots, z{\_}N) = (x{\_}1, {\{}$\backslash$textbackslash{\}}cdots, x{\_}m, y{\_}1, {\{}$\backslash$textbackslash{\}}cdots, y{\_}n) represent an observation on the {\{}NN{\}} random variables and let u(z)=(1/m)mâi=1ziâ(1/n)Nâi=m+1zi=ËxâËyu(z) = (1/m) {\{}$\backslash$textbackslash{\}}sum{\{}$\backslash$textasciicircum{\}}m{\_}{\{}i = 1{\}} z{\_}i - (1/n) {\{}$\backslash$textbackslash{\}}sum{\{}$\backslash$textasciicircum{\}}N{\_}{\{}i = m + 1{\}} z{\_}i = {\{}$\backslash$textbackslash{\}}bar x - {\{}$\backslash$textbackslash{\}}bar y. Consider the r=N!Nr = N! N-tuples obtained from (z1,â¯,{\{}zN{\}})(z{\_}1, {\{}$\backslash$textbackslash{\}}cdots, z{\_}N) by making all permutations of the indices (1,â¯,N)(1, {\{}$\backslash$textbackslash{\}}cdots, N). Since we assume continuous cdf's, then with probability one, these {\{}rNr{\}} N-tuples will be distinct. Denote them by z(1),â¯,z(r)z{\{}$\backslash$textasciicircum{\}}{\{}(1){\}}, {\{}$\backslash$textbackslash{\}}cdots, z{\{}$\backslash$textasciicircum{\}}{\{}(r){\}}, and suppose that they have been ordered so that u(z(1)â§â¯â§u(z(r))u(z{\{}$\backslash$textasciicircum{\}}{\{}(1){\}} {\{}$\backslash$textbackslash{\}}geqq {\{}$\backslash$textbackslash{\}}cdots {\{}$\backslash$textbackslash{\}}geqq u(z{\{}$\backslash$textasciicircum{\}}{\{}(r){\}}). Notice that since ËxâËy=(1/m)Nâi=1ziâ(N/m)Ëy=(N/n)Ëxâ(1/n)Nâi=1zi,{\{}$\backslash$textbackslash{\}}bar x - {\{}$\backslash$textbackslash{\}}bar y = (1/m) {\{}$\backslash$textbackslash{\}}sum{\{}$\backslash$textasciicircum{\}}N{\_}{\{}i = 1{\}} z{\_}i - (N/m){\{}$\backslash$textbackslash{\}}bar y = (N/n){\{}$\backslash$textbackslash{\}}bar x - (1/n) {\{}$\backslash$textbackslash{\}}sum{\{}$\backslash$textasciicircum{\}}N{\_}{\{}i = 1{\}} z{\_}i, the same ordering can be induced by choosing u(z)=cËxu(z) = c{\{}$\backslash$textbackslash{\}}bar x or u(z)=âcËyu(z) = - c{\{}$\backslash$textbackslash{\}}bar y for any c{\{}{\textgreater}{\}}0c {\{}{\textgreater}{\}} 0. Assuming that the cdf's of X1,Y1X{\_}1, Y{\_}1 are of the form F(x),F(xâ$\Delta$)F(x), F(x - {\{}$\backslash$textbackslash{\}}Delta) respectively, Pitman [2] suggested essentially the following test of the hypothesis Hâ²H' that $\Delta$=0{\{}$\backslash$textbackslash{\}}Delta = 0. Select a set of k(k{\{}{\textgreater}{\}}0)k (k {\{}{\textgreater}{\}} 0) integers i1,â¯,ik,(1â¦i1{\{}{\textless}{\}}â¯{\{}{\textless}{\}}ikâ¦r)i{\_}1, {\{}$\backslash$textbackslash{\}}cdots, i{\_}k, (1 {\{}$\backslash$textbackslash{\}}leqq i{\_}1 {\{}{\textless}{\}} {\{}$\backslash$textbackslash{\}}cdots {\{}{\textless}{\}} i{\_}k {\{}$\backslash$textbackslash{\}}leqq r). If the observed zz is one of the points z(i1),â¯,z(ik)z{\{}$\backslash$textasciicircum{\}}{\{}(i{\_}1){\}}, {\{}$\backslash$textbackslash{\}}cdots, z{\{}$\backslash$textasciicircum{\}}{\{}(i{\_}k){\}}, reject Hâ²H', otherwise accept. When Hâ²H' is true, the type one error does not depend on the specific form of the distribution of the {\{}XX{\}}'s and the {\{}YY{\}}'s and is in fact equal to k/rk/r. The choice of the rejection set i1,â¯,iki{\_}1, {\{}$\backslash$textbackslash{\}}cdots, i{\_}k should depend on the alternative hypothesis. For instance, if the experimenter wants protection against the alternative that the "{\{}XX{\}}'s tend to be larger than the {\{}YY{\}}'s," then the labels 1,â¯,k1, {\{}$\backslash$textbackslash{\}}cdots, k might be reasonable. For the alternative that the "{\{}XX{\}}'s tend to be smaller than the {\{}YY{\}}'s" the analogous procedure is to use the other tail, râk+1,â¯,rr - k + 1, {\{}$\backslash$textbackslash{\}}cdots, r. Against both alternatives, a two-tail procedure could be used. Lehmann and Stein have shown in [1] that in the class of all tests (of size $\alpha$=k/r{\{}$\backslash$textbackslash{\}}alpha = k/r) of the hypothesis H:the distribution {\{}ofX{\}}1â¯,Xm,Y1,â¯,Ynis invariant under all permutations,H: {\{}$\backslash$textbackslash{\}}text{\{}the distribution of{\}} X{\_}1 {\{}$\backslash$textbackslash{\}}cdots, X{\_}m, Y{\_}1, {\{}$\backslash$textbackslash{\}}cdots, Y{\_}n {\{}$\backslash$textbackslash{\}}text{\{}is invariant under all permutations{\}}, the single-tail test based on 1,â¯,k1, {\{}$\backslash$textbackslash{\}}cdots, k is uniformly most powerful against the alternatives that F1F{\_}1 is an N($\theta$,$\sigma$)N({\{}$\backslash$textbackslash{\}}theta, {\{}$\backslash$textbackslash{\}}sigma) cdf, F2F{\_}2 is an N($\theta$+$\Delta$,$\sigma$)N({\{}$\backslash$textbackslash{\}}theta + {\{}$\backslash$textbackslash{\}}Delta, {\{}$\backslash$textbackslash{\}}sigma) cdf, $\Delta${\{}{\textless}{\}}0{\{}$\backslash$textbackslash{\}}Delta {\{}{\textless}{\}} 0; the test based on râk+1,â¯,rr - k + 1, {\{}$\backslash$textbackslash{\}}cdots, r is uniformly most powerful for $\Delta${\{}{\textgreater}{\}}0{\{}$\backslash$textbackslash{\}}Delta {\{}{\textgreater}{\}} 0. A practical shortcoming of this procedure is the great difficulty in enumerating the points z(i)z{\{}$\backslash$textasciicircum{\}}{\{}(i){\}} and the evaluation of u(z(i))u(z{\{}$\backslash$textasciicircum{\}}{\{}(i){\}}) for each of them. For instance, even after eliminating those permutations which always give the same value of uu, then for sample sizes m=n=5m = n = 5, there are (105)=252{\{}$\backslash$textbackslash{\}}binom{\{}10{\}}{\{}5{\}} = 252 permutations to examine, and for sample sizes m=n=10m = n = 10, there are (2010)=184,765{\{}$\backslash$textbackslash{\}}binom{\{}20{\}}{\{}10{\}} = 184,765 permutations to examine. In the following section, we propose the almost obvious procedure of examining a "random sample" of permutations and making the decision to accept or reject {\{}HH{\}} on the basis of those permutations only. Bounds are determined for the ratio of the power of the original procedure to the modified one. Some numerical values of these bounds are given in Table 1. The bounds there listed correspond to tests which in both original and modified form have size $\alpha${\{}$\backslash$textbackslash{\}}alpha, and for which the modified test is based on a random sample of ss permutations drawn with replacement. These have been computed for a certain class of alternatives which is described below. For simplicity, we have restricted the main exposition to the two-sample problem. In Section 5, we point out extensions to the more general hypotheses of invariance studied in [1].},
author = {Dwass, Meyer},
doi = {10.1214/aoms/1177707045},
issn = {0003-4851, 2168-8990},
number = {1},
pages = {181--187},
title = {{Modified Randomization Tests for Nonparametric Hypotheses}},
volume = {28}
}
@book{zambrano-bigiarini_hydropso:_2014,
author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
title = {{{\{}hydroPSO{\}}: Particle Swarm Optimisation, with focus on Environmental Models}},
url = {http://www.rforge.net/hydroPSO, http://cran.r-project.org/web/packages/hydroPSO}
}
@book{willighagen_genalg:_2015,
author = {Willighagen, Egon and Ballings, Michel},
title = {{genalg: R Based Genetic Algorithm}},
url = {https://cran.r-project.org/package=genalg}
}
@article{kirkpatrick_optimization_1983,
abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
doi = {10.1126/science.220.4598.671},
issn = {0036-8075},
number = {4598},
pages = {671--680},
pmid = {17813860},
title = {{Optimization by simulated annealing}},
volume = {220}
}
@article{dufour_wald_2013,
abstract = {Wald-type tests are convenient because they allow one to test a wide array of linear and nonlinear restrictions from a single unrestricted estimator; we focus on the problem of implementing Wald-type tests for nonlinear restrictions. We provide examples showing that Wald statistics in non-regular cases can have several asymptotic distributions; the usual critical values based on a chi-square distribution can both lead to under-rejections and over-rejections; indeed, the Wald statistic may diverge under the null hypothesis. We study the asymptotic distribution of Wald-type statistics for the class of polynomial restrictions and show that the Wald statistic either has a non-degenerate asymptotic distribution, or diverges to infinity. We provide conditions for convergence and a general characterization of this distribution. We provide bounds on the asymptotic distribution (when it exists). In several cases of interest, this bound yields an easily available conservative critical value. We propose an adaptive consistent strategy for determining whether the asymptotic distribution exists and which form it takes.},
author = {Dufour, Jean-Marie and Renault, Eric and Zinde-Walsh, Victoria},
keywords = {62FO3,Mathematics - Statistics Theory},
title = {{Wald tests when restrictions are locally singular}}
}
@book{trautmann_cmaes:_2011,
author = {Trautmann, Heike and Mersmann, Olaf and Arnu, David},
title = {{cmaes: Covariance Matrix Adapting Evolutionary Strategy}},
url = {https://cran.r-project.org/package=cmaes}
}
@article{kirkpatrick_optimization_1984,
author = {Kirkpatrick, Scott},
number = {5},
pages = {975--986},
title = {{Optimization by simulated annealing: Quantitative studies}},
volume = {34}
}
@book{r_core_team_r:_2016,
author = {{R Core Team}},
publisher = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {https://www.r-project.org/}
}
@book{ciupke_psoptim:_2016,
author = {Ciupke, Krzysztof},
title = {{psoptim: Particle Swarm Optimization}},
url = {https://cran.r-project.org/package=psoptim}
}
@book{davison_bootstrap_1997,
author = {Davison, A C and Hinkley, D V},
publisher = {Cambridge University Press},
title = {{Bootstrap Methods and Their Applications}},
url = {http://statwww.epfl.ch/davison/BMA/}
}
@book{wickham_devtools:_2016,
author = {Wickham, Hadley and Chang, Winston},
title = {{devtools: Tools to make developing R code easier}}
}
@book{bendtsen_pso:_2012,
author = {Bendtsen, Claus},
title = {{pso: Particle Swarm Optimization}},
url = {https://cran.r-project.org/package=pso}
}
@article{dufour_rank-robust_2016,
author = {Dufour, Jean-Marie and Val{\'{e}}ry, Pascale},
title = {{Rank-robust Wald-type tests: a regularization approach}}
}
@book{wickham_ggplot2:_2009,
author = {Wickham, Hadley},
isbn = {978-0-387-98140-6},
publisher = {Springer-Verlag New York},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {http://ggplot2.org}
}
@article{haldrup_robustness_2002,
author = {Haldrup, Niels and Lildholdt, Peter},
doi = {10.1111/1467-9892.00260},
issn = {1467-9892},
keywords = {DickeyâFuller test,I(1) versus I(2),PhillipsâPerron test,Unit root tests},
number = {2},
pages = {155--171},
title = {{On the Robustness of Unit Root Tests in the Presence of Double Unit Roots}},
volume = {23}
}
@article{martin_mcmcpack:_2011,
author = {Martin, Andrew D and Quinn, Kevin M and Park, Jong Hee},
number = {9},
pages = {22},
title = {{{\{}MCMCpack{\}}: Markov Chain Monte Carlo in R}},
url = {http://www.jstatsoft.org/v42/i09/},
volume = {42}
}
@article{zambrano-bigiarini_model-independent_2013,
author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
pages = {5--25},
title = {{A model-independent Particle Swarm Optimisation software for model calibration}},
url = {http://dx.doi.org/10.1016/j.envsoft.2013.01.004},
volume = {43}
}
@article{cerny_thermodynamical_1985,
abstract = {We present a Monte Carlo algorithm to find approximate solutions of the traveling salesman problem. The algorithm generates randomly the permutations of the stations of the traveling salesman trip, with probability depending on the length of the corresponding route. Reasoning by analogy with statistical thermodynamics, we use the probability given by the Boltzmann-Gibbs distribution. Surprisingly enough, using this simple algorithm, one can get very close to the optimal solution of the problem or even find the true optimum. We demonstrate this on several examples.We conjecture that the analogy with thermodynamics can offer a new insight into optimization problems and can suggest efficient algorithms for solving them.},
author = {{\v{C}}ern{\'{y}}, V},
doi = {10.1007/BF00940812},
issn = {0022-3239, 1573-2878},
number = {1},
pages = {41--51},
shorttitle = {Thermodynamical approach to the traveling salesman},
title = {{Thermodynamical approach to the traveling salesman problem: An efficient simulation algorithm}},
url = {http://link.springer.com/article/10.1007/BF00940812},
volume = {45}
}
@book{clayden_soma:_2014,
author = {Clayden, Jon and Zelinka, Ivan},
title = {{soma: General-Purpose Optimisation With the Self-Organising Migrating Algorithm}},
url = {https://cran.r-project.org/package=soma}
}
@article{behrens_beitrag_1929,
author = {Behrens, W U},
pages = {807--837},
title = {{Ein Beitrag zur Fehlerberechnung bei wenigen Beobachtungen}},
volume = {68}
}
@misc{boudjellaba_simplified_1992,
abstract = {No abstract is available for this item.},
author = {Boudjellaba, H and Dufour, J M and Roy, R},
institution = {Universite de Montreal, Departement de sciences economiques},
keywords = {econometrics,{\{}ECONOMIC{\}} {\{}MODELS{\}}},
number = {9236},
title = {{Simplified Conditions for Non-Causality Between Vectors in Multivariate Arma Models}},
type = {Cahiers de recherche},
url = {https://ideas.repec.org/p/mtl/montde/9236.html}
}
@article{scrucca_ga:_2013,
author = {Scrucca, Luca},
number = {4},
pages = {1--37},
title = {{{\{}GA{\}}: A Package for Genetic Algorithms in R}},
url = {http://www.jstatsoft.org/v53/i04/},
volume = {53}
}
@article{mullen_continuous_2014,
author = {Mullen, Katharine M and Others},
number = {6},
pages = {1--45},
title = {{Continuous global optimization in R}},
volume = {60}
}
@article{pantula_testing_1989,
abstract = {Let Yt satisfy the stochastic difference equation Yt=$\Sigma$ j=1 p$\alpha$ {\{}jYt{\}}-j+$\Sigma$ j=1 q$\theta$ jet-j+et, for t = 1,2,..., where et are independent and identically distributed random variables with mean zero and variance $\sigma$ 2 and the initial conditions (Y-p+1,...,Y0) are fixed constants. It is assumed that the process is invertible and that the true, but unknown, roots m1,m2,...,mp of mp-$\Sigma$ j=1 p$\alpha$ jmp-j=0 satisfy the hypothesis Hd: m1=...=md=1 and {\{}$\backslash$textbar{\}}m{\$}{\_}{\{}\backslashtextrm{\{}j{\}}{\}}{\$}{\{}$\backslash$textbar{\}}{\{}{\textless}{\}}1 for j = d + 1,...,p. We present a reparameterization of the model for Yt that is convenient for testing the hypothesis Hd. We consider the asymptotic properties of (i) a likelihood ratio type "F-statistic" for testing the hypothesis Hd, (ii) a likelihood ratio type t-statistic for testing the hypothesis Hd against the alternative Hd-1. Using these asymptotic results, we obtain two sequential testing procedures that are asymptotically consistent.},
author = {Pantula, Sastry G},
issn = {02664666, 14694360},
number = {2},
pages = {256--271},
title = {{Testing for Unit Roots in Time Series Data}},
url = {http://www.jstor.org/stable/3532498},
volume = {5}
}
@incollection{gourieroux_size_2013,
abstract = {Let us assume that {\^{A}} {\{}TA{\}}{\{}$\backslash$textasciicircum{\}}T{\{}$\backslash$textbackslash{\}}hat{\{}A{\}}{\_}T is a consistent, asymptotically normal estimator of a matrix A (where T is the sample size), this paper shows that test statistics used in empirical work to test 1) the noninvertibility of A, i.e. det A = 0, 2) the positivite semi-definiteness A {\{}{\textgreater}{\}} {\{}{\textgreater}{\}} 0, have a different asymptotic distribution in the case where A = 0 than in the case where A â  0. Moreover, the paper shows that an estimator of A constrained by symmetry or reduced rank has a different asymptotic distribution when A = 0 than when A â  0. The implication is that inference procedures that use critical values equal to appropriate quantiles from the distribution when A â  0 may be size distorted. The paper points out how the above statistical problems arise in standard models in Finance in the analysis of risk effects.A Monte Carlo study explores how the asymptotic results are reflected in finite sample.},
author = {Gourieroux, Christian and Jasiak, Joann},
booktitle = {Uncertainty Analysis in Econometrics with Applications},
editor = {Huynh, Van-Nam and Kreinovich, Vladik and Sriboonchitta, Songsak and Suriya, Komsan},
isbn = {978-3-642-35442-7 978-3-642-35443-4},
keywords = {Artificial Intelligence (incl. Robotics),Boundary,C10,C32,Computational Intelligence,G10,G12,Identifiability,Invertibility Test,Multivariate Volatility,Risk Premium,Volatility Transmission,econometrics,{\{}BEKK{\}} Model},
number = {200},
pages = {91--118},
publisher = {Springer Berlin Heidelberg},
series = {Advances in Intelligent Systems and Computing},
title = {{Size Distortion in the Analysis of Volatility and Covolatility Effects}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-35443-4{\_}7}
}
@article{smirnoff_sur_1939,
author = {Smirnoff, N},
number = {1},
pages = {3--26},
title = {{Sur les {\'{e}}carts de la courbe de distribution empirique}},
volume = {48}
}
@inproceedings{shi_modified_1998,
author = {Shi, Yuhui and Eberhart, Russell},
booktitle = {Evolutionary Computation Proceedings, 1998. {\{}IEEE{\}} World Congress on Computational Intelligence., The 1998 {\{}IEEE{\}} International Conference on},
pages = {69--73},
publisher = {IEEE},
title = {{A modified particle swarm optimizer}}
}
@book{mersmann_microbenchmark:_2015,
author = {Mersmann, Olaf},
title = {{microbenchmark: Accurate Timing Functions}},
url = {https://cran.r-project.org/package=microbenchmark}
}
@book{geyer_mcmc:_2015,
author = {Geyer, Charles J and Johnson, Leif T},
title = {{mcmc: Markov Chain Monte Carlo}},
url = {https://cran.r-project.org/package=mcmc}
}
@book{price_differential_2006,
author = {Price, Kenneth V and Storn, Rainer M and Lampinen, Jouni A},
publisher = {Springer-Verlag},
series = {Natural Computing},
title = {{Differential Evolution - A Practical Approach to Global Optimization}}
}
@book{wuertz_funitroots:_2013,
author = {Wuertz, Diethelm and Et al.},
title = {{{\{}fUnitRoots{\}}: Trends and Unit Roots}},
url = {https://cran.r-project.org/package=fUnitRoots}
}
@book{venables_modern_2002,
author = {Venables, W N and Ripley, B D},
edition = {Fourth},
publisher = {Springer},
title = {{Modern Applied Statistics with S}},
url = {http://www.stats.ox.ac.uk/pub/MASS4}
}
@book{caffo_exactloglintest:_2013,
author = {Caffo, Brian},
title = {{{\{}exactLoglinTest{\}}: Monte Carlo Exact Tests for Log-linear models}},
url = {https://cran.r-project.org/package=exactLoglinTest}
}
@article{yang_xiang_generalized_2013,
author = {{Yang Xiang} and Gubian, Sylvain and Suomela, Brian and Hoeng, Julia},
title = {{Generalized Simulated Annealing for Efficient Global Optimization: the {\{}GenSA{\}} Package for R.}},
url = {http://journal.r-project.org/}
}
@book{bergmeir_continuous_2012,
author = {Bergmeir, Christoph and Molina, Daniel and Be{\'{n}}itez, Jo{\'{s}}e M},
title = {{Continuous Optimization using Memetic Algorithms with Local Search Chains ({\{}MA{\}}-{\{}LS{\}}-Chains) in R}}
}
@article{welch_generalization_1947,
author = {Welch, B L},
doi = {10.2307/2332510},
pages = {28--35},
title = {{The generalization of 'Student's' problem when several different population variances are involved}},
volume = {34}
}
@book{canty_boot:_2016,
author = {Canty, Angelo and Ripley, B D},
title = {{boot: Bootstrap R (S-Plus) Functions}}
}
@book{gilli_numerical_2011,
author = {Gilli, Manfred and Maringer, Dietmar and Schumann, Enrico},
publisher = {Academic Press},
title = {{Numerical Methods and Optimization in Finance}},
url = {http://nmof.net}
}
@article{fernandez-i-marin_ggmcmc:_2016,
author = {Fern{\'{a}}ndez-i-Mar{\'{i}}n, Xavier},
doi = {10.18637/jss.v070.i09},
number = {9},
pages = {1--20},
title = {{ggmcmc: Analysis of {\{}MCMC{\}} Samples and Bayesian Inference}},
volume = {70}
}
@article{dufour_exact_2001,
author = {Dufour, Jean-Marie and Farhat, Abdeljelil},
title = {{Exact Nonparametric Two-Sample Homogeneity Tests for Possibly Discrete Distributions.}}
}
@article{dufour_monte_2006,
abstract = {The technique of Monte Carlo ({\{}MC{\}}) tests [Dwass (1957), Barnard (1963)] provides an attractive method of building exact tests from statistics whose finite sample distribution is intractable but can be simulated (provided it does not involve nuisance parameters). We extend this method in two ways: first, by allowing for {\{}MC{\}} tests based on exchangeable possibly discrete test statistics; second, by generalizing the method to statistics whose null distributions involve nuisance parameters (maximized {\{}MC{\}} tests, {\{}MMC{\}}). Simplified asymptotically justified versions of the {\{}MMC{\}} method are also proposed and it is shown that they provide a simple way of improving standard asymptotics and dealing with nonstandard asymptotics (e.g., unit root asymptotics). Parametric bootstrap tests may be interpreted as a simplified version of the {\{}MMC{\}} method (without the general validity properties of the latter).{\{}{\textless}{\}}P{\{}{\textgreater}{\}}(This abstract was borrowed from another version of this item.)},
author = {Dufour, Jean-Marie},
number = {2},
pages = {443--477},
shorttitle = {Monte Carlo tests with nuisance parameters},
title = {{Monte Carlo tests with nuisance parameters: A general approach to finite-sample inference and nonstandard asymptotics}},
volume = {133}
}
